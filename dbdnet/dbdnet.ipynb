{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import kornia.augmentation as K\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 48\n",
    "NUM_CLASSES = 21\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image):\n",
    "    # Apply random horizontal flip with probability 0.5\n",
    "    image = K.RandomHorizontalFlip(p=0.5)(image)\n",
    "    # Apply random affine transformation with rotation angle range [-15,15] degrees\n",
    "    image = K.RandomAffine(degrees=(-15, 15))(image)\n",
    "    # Apply random color jitter with brightness range [0.8,1.2]\n",
    "    image = K.ColorJitter(brightness=(0.8, 1.2))(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_int(labels):\n",
    "    label_dict = {}\n",
    "    rev_label_dict = {}\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_dict[label] = idx\n",
    "        rev_label_dict[idx] = label\n",
    "\n",
    "    return label_dict, rev_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dirs, label2idx):\n",
    "        super().__init__()\n",
    "        self.data_dirs = data_dirs\n",
    "        self.label2idx = label2idx\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for dir in self.data_dirs:\n",
    "            for filename in os.listdir(dir):\n",
    "                # Read webp image using Pillow\n",
    "                image = Image.open(os.path.join(dir, filename))\n",
    "                # Resize image to IMAGE_SIZE x IMAGE_SIZE\n",
    "                image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                # Convert image to tensor and normalize iter\n",
    "                image = TF.to_grayscale(image)\n",
    "                image = TF.to_tensor(image)\n",
    "                mean, std = image.mean([1,2]), image.std([1,2])\n",
    "                image = TF.normalize(image, mean=mean, std=std)\n",
    "                self.images.append(image)\n",
    "                # Use filename as label (without extension)\n",
    "                label = os.path.splitext(filename)[0]\n",
    "                # Convert label to integer (labels should go from 0 to NUM_CLASSES - 1)\n",
    "                label = self.label2idx[label]\n",
    "                self.labels.append(label)\n",
    "        # Split images and labels into train and val sets\n",
    "        split_idx = int(len(self.images) * 0.6)\n",
    "        self.train_images = self.images[:split_idx]\n",
    "        self.train_labels = self.labels[:split_idx]\n",
    "        self.val_images = self.images[split_idx:]\n",
    "        self.val_labels = self.labels[split_idx:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Create a dataset from train images and labels\n",
    "        train_dataset = TensorDataset(torch.stack(self.train_images), torch.tensor(self.train_labels))\n",
    "        train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Create a TensorDataset from val images and labels\n",
    "        val_dataset = TensorDataset(torch.stack(self.val_images), torch.tensor(self.val_labels))\n",
    "        # Create a dataloader from val dataset with shuffle=False and batch_size=BATCH_SIZE\n",
    "        val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(32 * IMAGE_SIZE // 4 * IMAGE_SIZE // 4, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 32 * IMAGE_SIZE // 4 * IMAGE_SIZE // 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get images and labels from batch\n",
    "        images, labels = batch\n",
    "        # Get logits from model\n",
    "        logits = self(images)\n",
    "        # Compute cross entropy loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        # Log loss to tensorboard\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get images and labels from batch\n",
    "        images, labels = batch\n",
    "        # Get logits from model\n",
    "        logits = self(images)\n",
    "        # Compute cross entropy loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        # Log loss to tensorboard\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer (e.g., Adam)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation block\n",
    "for filename in os.listdir('images'):\n",
    "    image = Image.open(os.path.join('images', filename))\n",
    "    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = TF.to_tensor(image)[0:3,:,:]\n",
    "    mean, std = image.mean([1,2]), image.std([1,2])\n",
    "    image = TF.normalize(image, mean=mean, std=std)\n",
    "\n",
    "    transformed_image = transform(image)\n",
    "    pil_image = TF.to_pil_image(transformed_image.squeeze(0))\n",
    "    pil_image.save(f'processed2/{os.path.splitext(filename)[0]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for filename in os.listdir('processed'):\n",
    "    # Read webp image using Pillow\n",
    "    image = Image.open(os.path.join('processed', filename))\n",
    "    image = TF.to_tensor(image)\n",
    "    label = os.path.splitext(filename)[0]\n",
    "    # Convert label to integer (labels should go from 0 to NUM_CLASSES - 1)\n",
    "    labels.append(label)\n",
    "\n",
    "label2id, id2label = convert_label_to_int(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | conv1 | Conv2d    | 160   \n",
      "1 | pool1 | MaxPool2d | 0     \n",
      "2 | conv2 | Conv2d    | 4.6 K \n",
      "3 | pool2 | MaxPool2d | 0     \n",
      "4 | fc1   | Linear    | 589 K \n",
      "5 | fc2   | Linear    | 2.7 K \n",
      "------------------------------------\n",
      "597 K     Trainable params\n",
      "0         Non-trainable params\n",
      "597 K     Total params\n",
      "2.390     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a49369c94a8d43c2824b2ff0a9a0f6d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32188019b6d942778098b09cefd66468"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Authority\\Desktop\\dbdnet\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "print('ciao')\n",
    "data_module = ImageClassificationDataModule(['images', 'processed', 'processed2', 'test'], label2id)\n",
    "model = ImageClassificationModel()\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'FulliconStatusEffects_oblivious'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = Image.open('test/FulliconStatusEffects_broken.png')\n",
    "test_image = TF.center_crop(test_image, [IMAGE_SIZE,IMAGE_SIZE])\n",
    "test_image.save('test/cocco.png')\n",
    "test_image = TF.to_grayscale(test_image)\n",
    "test_image.save('test/cocco.png')\n",
    "test_image = TF.to_tensor(test_image)\n",
    "result = model(test_image)\n",
    "res_idx = np.argmax(result.detach())\n",
    "id2label[res_idx.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
